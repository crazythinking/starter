#kafka配置，更多配置请参考：KafkaProperties
spring:
  kafka:
    #公共参数，其他的timeout.ms, request.timeout.ms, metadata.fetch.timeout.ms保持默认值
    properties:
      #指定producer在发送批量消息前等待的时间，当设置后，即便没有达到批量消息的指定大小(batch-size)，到达时间后生产者也会发送批量消息到broker。
      #默认情况下，生产者的发送消息线程只要空闲了就会发送消息，即便只有一条消息。设置这个参数后，发送线程会等待一定的时间，这样可以批量发送消息增加吞吐量，但同时也会增加延迟。
      linger.ms: 50 #默认值：0毫秒，当消息发送比较频繁时，增加一些延迟可增加吞吐量和性能。
      #指定producer在一个TCP connection上可同时发送多少条消息到broker并且等待broker响应，设置较高的值可以提高吞吐量，但同时也会增加内存消耗。
      #另外，如果设置非常高反而也会降低吞吐量，因为批量消息效率降低。设置为1，可以保证发送到broker的顺序和调用send方法顺序一致，即便出现失败重试的情况也是如此。
      #注意：当前消息符合at-least-once，自kafka1.0.0以后，为保证消息有序以及exactly once，这个配置可适当调大为5。
      #1即表示producer在connection上发送一条消息，至少要等到这条消息被broker确认收到才继续发送下一条，因此是有序的。
      max.in.flight.requests.per.connection: 1 #默认值：5

    #生产者的配置，可参考org.apache.kafka.clients.producer.ProducerConfig
    producer:
      #这个参数可以是任意字符串，它是broker用来识别消息是来自哪个客户端的。在broker进行打印日志、衡量指标或者配额限制时会用到。
      client-id: ${spring.application.name}-producer #方便kafka server打印日志定位请求来源
      #0，producer不等待broker的响应，效率最高，但是消息很可能会丢；
      #1，leader broker收到消息后，不等待其他follower的响应，即返回ack；如果此时leader断电，数据会丢失；
      #-1，leader broker收到消息后，挂起，等待所有ISR列表中的follower返回结果后，再返回ack；ISR由min.insync.replicas最小副本决定；
      acks: -1 #默认值：1
      #当生产者发送消息收到一个可恢复异常时，会进行重试，用于指定重试的次数。
      #需要结合retry.backoff.ms（重试等待间隔）来使用，建议总的重试时间比集群重新选举leader的时间长，这样可以避免生产者过早结束重试导致失败。
      #另外当开启重试时，若未设置max.in.flight.requests.per.connection=1，则可能出现发往同一个分区的两批消息的顺序出错；
      #比如，第一批发送失败了，第二批成功了，然后第一批重试成功了，此时两者的顺序就颠倒了。
      retries: 2  #发送失败时重试多少次，0=禁用重试（默认值）
      #默认情况下消息是不压缩的，此参数可指定采用何种算法压缩消息；可取值：none,snappy,gzip,lz4。
      #snappy压缩算法由Google研发，这种算法在性能和压缩比取得比较好的平衡；gzip消耗更多的CPU资源，但是压缩效果也是最好的。
      compression-type: none #如果不开启压缩，可设置为none（默认值），比较大的消息可开启。
      #当多条消息发送到一个分区时，Producer会进行批量发送，这个参数指定了批量消息大小的上限（以字节为单位）。
      #当批量消息达到这个大小时，Producer会一起发送到broker；但即使没有达到这个大小，生产者也会有定时机制来发送消息，避免消息延迟过大。
      batch-size: 16384 #默认16K，值越小延迟越低，但是吞吐量和性能会降低。0=禁用批量发送
      #这个参数设置Producer暂存待发送消息的缓冲区内存的大小，如果应用调用send方法的速度大于Producer发送的速度，那么调用会阻塞一定（max.block.ms）时间后抛出异常。
      buffer-memory: 33554432 #缓冲区默认大小32M
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer

    #消费者的配置，可参考：org.apache.kafka.clients.consumer.ConsumerConfig
    consumer:
      #可以为任意值，用来指明消息从哪个客户端发出，一般会在打印日志、衡量指标、分配配额时使用。
      #暂不用提供clientId，2.x版本可放出来，1.x有多个topic且concurrency>1会出现JMX注册时异常
      client-id: ${spring.application.name}-consumer
      #当Kafka中没有初始偏移量或服务器上不再存在当前consumer对应偏移量时的策略；
      #可以取值为latest（从最新的消息开始消费）,earliest（从最老的消息开始消费）,none（如果无offset就抛出异常）
      auto-offset-reset: earliest #默认值：latest
      #是否自动提交offset
      #true，可能存在消费过程未成功（比如抛出异常），commit消息已经提交了，此时消息就丢失了；
      #false，可以保证消息“至少被消费一次”(at least once)，但此时需要在消费端需要解决幂等问题；
      enable-auto-commit: true
      #周期性自动提交的间隔，单位毫秒
      #auto-commit-interval: 2000 #默认值：5000
      #允许消费者指定从broker读取消息时最小的Payload的字节数。
      #当消费者从broker读取消息时，如果数据字节数小于这个阈值，broker会等待直到有足够的数据，然后才返回给消费者。
      #对于写入量不高的主题来说，其可以减少broker和消费者的压力，因为减少了往返的时间。而对于有大量消费者的主题来说，则可以明显减轻broker压力。
      fetch-min-size: 1 #默认值： 1B
      #上面的fetch-min-size指定了消费者读取的最小数据量，而这个参数则指定了消费者读取时最长等待时间，从而避免长时间阻塞。这个参数默认为500ms。
      fetch-max-wait: 500
      #这个参数控制一个poll()调用返回的记录数，即consumer每次批量拉多少条数据。
      max-poll-records: 500
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer

    listener:
      #创建多少个consumer，值必须小于等于Kafka Topic的分区数。
      ack-mode: MANUAL_IMMEDIATE
      concurrency: 1  #推荐设置为topic的分区数

    template:
      default-topic: ${spring.application.name}
